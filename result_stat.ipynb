{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:41:28.400489Z",
     "start_time": "2023-09-18T21:41:28.397861Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def compute_stats(file_path: str):\n",
    "    with open(file_path, 'r') as f:\n",
    "        full_results = yaml.load(f, yaml.Loader)\n",
    "    peritem_full_score = {}\n",
    "    peritem_get_score = {}\n",
    "    peritem_freq = {}\n",
    "    perlang_full_score = {}\n",
    "    perlang_get_score = {}\n",
    "    perlang_freq = {}\n",
    "    perarea_full_score = {}\n",
    "    perarea_get_score = {}\n",
    "    perarea_freq = {}\n",
    "    tot_score = 0.\n",
    "    full_score = 0.\n",
    "    \n",
    "    fields = ['keywords', 'blank_filling', 'unit_test', 'similarity', 'customized']\n",
    "    \n",
    "    for case_name, case_report in full_results.items():\n",
    "        case_full_score = case_report['full_score']\n",
    "        \n",
    "        # locate the instance with highest score\n",
    "        best_score = 0.\n",
    "        best_response_peritem_full_score = {}\n",
    "        best_response_peritem_get_score = {}\n",
    "        for response_report in case_report['detail']:\n",
    "            now_score = 0.\n",
    "            response_peritem_full_score = {}\n",
    "            response_peritem_get_score = {}\n",
    "            for field in fields:\n",
    "                if field + '_score' in response_report:\n",
    "                    now_score += response_report[field + '_score']\n",
    "                    response_peritem_full_score[field] = response_report[field + '_totscore']\n",
    "                    response_peritem_get_score[field] = response_report[field + '_score']\n",
    "            if now_score >= best_score:\n",
    "                best_score = now_score\n",
    "                best_response_peritem_full_score = response_peritem_full_score\n",
    "                best_response_peritem_get_score = response_peritem_get_score\n",
    "        \n",
    "        tot_case_score = sum(best_response_peritem_full_score.values())\n",
    "        for item in best_response_peritem_full_score:\n",
    "            best_response_peritem_full_score[item] *= case_full_score / tot_case_score\n",
    "            best_response_peritem_get_score[item] *= case_full_score / tot_case_score\n",
    "        \n",
    "        for item in best_response_peritem_full_score:\n",
    "            if item not in peritem_get_score:\n",
    "                peritem_get_score[item] = 0.\n",
    "                peritem_full_score[item] = 0.\n",
    "                peritem_freq[item] = 0.\n",
    "            peritem_get_score[item] += best_response_peritem_get_score[item]\n",
    "            peritem_full_score[item] += best_response_peritem_full_score[item]\n",
    "            peritem_freq[item] += 1\n",
    "        \n",
    "        now_score = case_report['now_score']\n",
    "        now_lang = case_report['lang']\n",
    "        now_area = case_report['type']\n",
    "        \n",
    "        tot_score += now_score\n",
    "        full_score += case_report['full_score']\n",
    "        \n",
    "        if now_lang not in perlang_get_score:\n",
    "            perlang_get_score[now_lang] = 0.\n",
    "            perlang_full_score[now_lang] = 0.\n",
    "            perlang_freq[now_lang] = 0.\n",
    "        \n",
    "        perlang_get_score[now_lang] += now_score\n",
    "        perlang_full_score[now_lang] += case_full_score\n",
    "        perlang_freq[now_lang] += 1.\n",
    "        \n",
    "        if now_area not in perarea_get_score:\n",
    "            perarea_get_score[now_area] = 0.\n",
    "            perarea_full_score[now_area] = 0.\n",
    "            perarea_freq[now_area] = 0.\n",
    "        \n",
    "        perarea_get_score[now_area] += now_score\n",
    "        perarea_full_score[now_area] += case_full_score\n",
    "        perarea_freq[now_area] += 1.\n",
    "        \n",
    "    langs = list(perlang_get_score.keys())\n",
    "    areas = list(perarea_get_score.keys())\n",
    "    \n",
    "    return {\n",
    "        'tot_score': tot_score,\n",
    "        'tot_full_score': full_score,\n",
    "        'lang': langs,\n",
    "        'area': areas,\n",
    "        'field': fields,\n",
    "        'perarea_freq': perarea_freq,\n",
    "        'perarea_get_score': perarea_get_score,\n",
    "        'perarea_full_score': perarea_full_score,\n",
    "        'perlang_freq': perlang_freq,\n",
    "        'perlang_get_score': perlang_get_score,\n",
    "        'perlang_full_score': perlang_full_score,\n",
    "        'peritem_freq': peritem_freq,\n",
    "        'peritem_get_score': peritem_get_score,\n",
    "        'peritem_full_score': peritem_full_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c7777d0dd8ebea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:28.531785Z",
     "start_time": "2023-09-18T21:42:28.367693Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpt4_stats = compute_stats('results/suite_v1_avg_gpt-4_0.2_0.9_10.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "505a86a9bf1c1a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:28.925451Z",
     "start_time": "2023-09-18T21:42:28.769668Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpt35_stats = compute_stats('results/suite_v1_avg_gpt-3.5-turbo_0.2_0.9_10.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd6ff222d0e40501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:29.124794Z",
     "start_time": "2023-09-18T21:42:29.120703Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tab_gen(stats, cols):\n",
    "    cols = [''] + sum([[col, ''] for col in cols], []) + ['Full Score', 'Allocation']\n",
    "    lines = [cols]\n",
    "    # Tot score\n",
    "    lines.append(['Overall Score'] + sum([[stat['tot_score'], stat['tot_score'] / stats[0]['tot_full_score']] for stat in stats], []) + [stats[0]['tot_full_score'], ''])\n",
    "    # Score by Lang\n",
    "    lang_ranks = sorted(stats[0]['lang'], key=lambda x: stats[0]['perlang_full_score'][x], reverse=True)\n",
    "    lines += [['Lang: ' + lang] + sum([[stat['perlang_get_score'][lang], stat['perlang_get_score'][lang] / stats[0]['perlang_full_score'][lang]] for stat in stats], []) + [stats[0]['perlang_full_score'][lang], stats[0]['perlang_full_score'][lang] / stats[0]['tot_full_score']] for lang in lang_ranks]\n",
    "    # Score by Area\n",
    "    area_ranks = sorted(stats[0]['area'], key=lambda x: stats[0]['perarea_full_score'][x], reverse=True)\n",
    "    lines += [['Type: ' + area] + sum([[stat['perarea_get_score'][area], stat['perarea_get_score'][area] / stats[0]['perarea_full_score'][area]] for stat in stats], []) + [stats[0]['perarea_full_score'][area], stats[0]['perarea_full_score'][area] / stats[0]['tot_full_score']] for area in area_ranks]\n",
    "    # Score by Evaluation metric\n",
    "    item_ranks = sorted(stats[0]['peritem_full_score'].keys(), key=lambda x: stats[0]['peritem_full_score'][x], reverse=True)\n",
    "    lines += [['Metric: ' + item] + sum([[stat['peritem_get_score'][item], stat['peritem_get_score'][item] / stats[0]['peritem_full_score'][item]] for stat in stats], []) + [stats[0]['peritem_full_score'][item], stats[0]['peritem_full_score'][item] / stats[0]['tot_full_score']] for item in item_ranks]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5d618cda29ae711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:29.580975Z",
     "start_time": "2023-09-18T21:42:29.575334Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = tab_gen([gpt4_stats, gpt35_stats], ['gpt4', 'gpt3.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99c0caf0f0ece010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:29.950267Z",
     "start_time": "2023-09-18T21:42:29.943718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_csv(tab, path):\n",
    "    with open(path, 'w') as f:\n",
    "        s = ''\n",
    "        for row in tab:\n",
    "            for j, item in enumerate(row):\n",
    "                if j > 0: s += ','\n",
    "                if isinstance(item, str): \n",
    "                    s += item\n",
    "                elif isinstance(item, float): \n",
    "                    if j % 2 == 1: \n",
    "                        s += f'{item:.2f}' \n",
    "                    else: \n",
    "                        s += f'{item * 100.:.2f}%'\n",
    "                else: s += item\n",
    "            s += '\\n'\n",
    "        f.write(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc2e70394676fd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:30.402664Z",
     "start_time": "2023-09-18T21:42:30.399718Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",gpt4,,gpt3.5,,Full Score,Allocation\n",
      "Overall Score,21.74,54.36%,17.64,44.10%,40.00,\n",
      "Lang: javascript,6.07,55.15%,4.13,37.58%,11.00,27.50%\n",
      "Lang: python,6.02,66.89%,5.18,57.59%,9.00,22.50%\n",
      "Lang: web,3.28,54.64%,2.78,46.31%,6.00,15.00%\n",
      "Lang: dart,1.95,65.00%,2.12,70.56%,3.00,7.50%\n",
      "Lang: mobile,0.70,23.33%,0.00,0.00%,3.00,7.50%\n",
      "Lang: java,0.57,28.34%,0.53,26.25%,2.00,5.00%\n",
      "Lang: sql,0.29,28.57%,0.36,35.71%,1.00,2.50%\n",
      "Lang: swift,0.41,40.61%,0.21,20.84%,1.00,2.50%\n",
      "Lang: go,0.35,35.00%,0.47,47.50%,1.00,2.50%\n",
      "Lang: git,0.27,26.85%,0.26,26.25%,1.00,2.50%\n",
      "Lang: system,1.00,100.00%,1.00,100.00%,1.00,2.50%\n",
      "Lang: php,0.85,85.00%,0.60,60.00%,1.00,2.50%\n",
      "Type: code debugging,8.09,42.56%,7.17,37.76%,19.00,47.50%\n",
      "Type: knowledge question-answering,7.36,56.59%,5.77,44.41%,13.00,32.50%\n",
      "Type: code completion,6.30,78.75%,4.69,58.67%,8.00,20.00%\n",
      "Metric: keywords,20.24,72.01%,15.52,55.22%,28.10,70.25%\n",
      "Metric: unit_test,5.90,100.00%,5.90,100.00%,5.90,14.75%\n",
      "Metric: similarity,1.07,26.83%,0.81,20.26%,4.00,10.00%\n",
      "Metric: blank_filling,1.00,50.00%,0.43,21.43%,2.00,5.00%\n"
     ]
    }
   ],
   "source": [
    "print(to_csv(tab, 'result_avg.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e159e5e55b359fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:42:30.837807Z",
     "start_time": "2023-09-18T21:42:30.825139Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735559bfd56bc2bd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "d1f07590-5b7b-4753-908a-734dba0bf694",
  "kernelspec": {
   "display_name": "Python 3.11.5 ('text2sql': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3e9eccdb07730ec81860bbcc1a1b89e367e349a38a02546ba788e0242d52f32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
