Sure! Here's the code to split the dataset into training and validation sets:

```
from torch.utils.data import DataLoader, SubsetRandomSampler

# Set the split ratio
split_ratio = 0.8

# Split the dataset into training and validation sets
dataset_size = len(dataset)
indices = list(range(dataset_size))
split = int(np.floor(split_ratio * dataset_size))
np.random.shuffle(indices)
train_indices, val_indices = indices[:split], indices[split:]

# Define samplers for obtaining training and validation batches
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)

# Define data loaders for training and validation data
train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)
validation_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)
```

This code uses the `SubsetRandomSampler` class from PyTorch to randomly split the dataset into training and validation sets based on the split ratio. It then defines separate data loaders for the training and validation sets using the `DataLoader` class from PyTorch. The `SubsetRandomSampler` is used to sample the data from the dataset based on the indices obtained from the split. Finally, the `train_loader` and `validation_loader` variables are defined to store the data loaders for the training and validation sets, respectively.