Sure! Here's the code to split the dataset into training and validation sets:

```
from torch.utils.data import DataLoader, SubsetRandomSampler

# Set seed for reproducibility
np.random.seed(42)

# Define size of training and validation sets
dataset_size = len(dataset)
train_size = int(0.8 * dataset_size)
val_size = dataset_size - train_size

# Define indices for training and validation sets
indices = list(range(dataset_size))
np.random.shuffle(indices)
train_indices, val_indices = indices[:train_size], indices[train_size:]

# Define samplers for training and validation sets
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)

# Define data loaders for training and validation sets
train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)
val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)
```

You can use the `train_loader` and `val_loader` variables to iterate over the training and validation sets respectively.